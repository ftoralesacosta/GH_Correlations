{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inclusive UE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "require(['codemirror/mode/clike/clike'], function(Clike) { console.log('ROOTaaS - C++ CodeMirror module loaded'); });"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "IPython.CodeCell.config_defaults.highlight_modes['magic_text/x-c++src'] = {'reg':[/^%%cpp/]};"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to ROOTaaS 6.06/06\n"
     ]
    }
   ],
   "source": [
    "from array import array\n",
    "import itertools\n",
    "import time\n",
    "import math\n",
    "\n",
    "import sys\n",
    "#####For NERSC:####\n",
    "#sys.path.insert(0,'/usr/common/software/rootpy/')\n",
    "import root_numpy\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#import astroML.plotting as aml\n",
    "#import iminuit\n",
    "import pandas as pd\n",
    "import root_pandas as rpd\n",
    "from root_pandas import read_root\n",
    "import ROOT\n",
    "from ROOT import TH1D\n",
    "from ROOT import SetOwnership\n",
    "from matplotlib.ticker import NullFormatter\n",
    "from ROOT import TLatex\n",
    "%matplotlib inline                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2615\n",
      "InputData/13d_0GeVTrack_paired_large_0GeVTracks_Correlation_Lambda_0_to_300.root\n",
      "InputData/pp_MB_4GeV_Skim_Correlation_NN.root\n"
     ]
    }
   ],
   "source": [
    "Shower = \"NN\"\n",
    "#Shower = \"LO\"\n",
    "CorrectedP = True     #FALSE FOR HARDPROBES\n",
    "\n",
    "if (Shower == \"NN\"):\n",
    "    #pPb_File = 'InputData/pPb_SE_NN_Correlation_GMB_Ratio.root'\n",
    "    #pp_File = 'InputData/pp_SE_NN_Correlation_GMB_Ratio.root'\n",
    "    pPb_File = 'InputData/pPb_MB_4GeV_Skim_Correlation_NN.root'\n",
    "    pPb_File = 'InputData/pp_MB_4GeV_Skim_Correlation_NN.root'\n",
    "    pp_File = 'InputData/pp_SE_NN_Correlation_GMB_Ratio_Inclusive.root'\n",
    "    pp_File = 'InputData/13d_0GeVTrack_paired_large_0GeVTracks_Correlation_Lambda_0_to_300.root'\n",
    "    #pp_File = 'InputData/pp_SE_NN_Correlation_GMB_Ratio.root'\n",
    "    if (CorrectedP):\n",
    "        purity = 0.2615\n",
    "    else:\n",
    "        purity = 0.352546\n",
    "if (Shower == \"LO\"):\n",
    "    pPb_File = 'InputData/13def_SE_L0_Correlation_GMB_Ratio.root'\n",
    "    pp_File = 'InputData/pPb_SE_L0_Correlation_GMB_Ratio_Track.root'\n",
    "    #pp_File = \"InputData/17q_MB_0GeV_Skim_Correlation_L0.root\"\n",
    "    if (CorrectedP):\n",
    "        purity = 0.221083\n",
    "    else:\n",
    "        purity = 0.271083\n",
    "        \n",
    "print purity\n",
    "\n",
    "#pPb_File = 'InputData/13d_MB_0GeV_NN_15_20.root'\n",
    "#pp_File = 'InputData/17q_MB_0Gev_NN_15_20.root'\n",
    "        \n",
    "#pPb_File = 'InputData/13def_EMax_SE_GMB_Ratio.root'\n",
    "#pp_File = 'InputData/17q_SE_EMax_Correlation_GMB_Ratio.root'\n",
    "\n",
    "MC_File = 'InputData/18b10a_pthat_1_2_SE_NN_Correlation_GMB_Ratio.root'\n",
    "print pp_File\n",
    "print pPb_File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#delta_phi_centers= np.array([0.19634954084936207, 0.5890486225480862, 0.9817477042468103, 1.3744467859455345, 1.7671458676442586, 2.1598449493429825, 2.552544031041707, 2.945243112740431])\n",
    "\n",
    "####Ommiting first dphi bin######\n",
    "delta_phi_centers= np.array([0.5890486225480862, 0.9817477042468103, 1.3744467859455345, 1.7671458676442586, 2.1598449493429825, 2.552544031041707, 2.945243112740431])\n",
    "phi_width = [0.39269908169872414/2]*len(delta_phi_centers)\n",
    "\n",
    "###Array used for UE Error bar####\n",
    "ue_error_bar = np.array([0,0.05,0.1,0.15,0.2,0.25,0.3,0.39269908169872414,2*0.39269908169872414])\n",
    "\n",
    "zTbins = [0.05, 0.07670637, 0.11767734, 0.18053204, 0.27695915, 0.42489062, 0.65183634, 1]\n",
    "pTbins = [12,15,19,26,40]\n",
    "\n",
    "#####. Total Number of zT bins, max 7  #####\n",
    "N_pT_Bins = 4\n",
    "NzT = 6\n",
    "N_Eta_Bins = 14\n",
    "#####  Skip First N zT bins  #####\n",
    "zT_offset = 0\n",
    "\n",
    "zT_centers = np.zeros(NzT)\n",
    "zT_widths = np.zeros(NzT)\n",
    "for ztbin in range(zT_offset,NzT+zT_offset):\n",
    "    zT_centers[ztbin-zT_offset] = (zTbins[ztbin]+ zTbins[ztbin+1])/2\n",
    "    zT_widths[ztbin-zT_offset] = (zTbins[ztbin+1]-zTbins[ztbin])/2\n",
    "\n",
    "Corrections = [1,1.007,0.982,0.970,0.942,0.830,0.640]\n",
    "oneminFake = [1,0.982,0.980,0.978,0.970,0.915,0.812]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Get_NTriggers(filename,ipt, Signal_DNN=True): \n",
    "    file = ROOT.TFile(filename)\n",
    "    if (Signal_DNN == \"Inclusive\"):\n",
    "        ntrig_histo = file.Get('N_Inclusive_Triggers_pT%1.0f_%1.0f' %(pTbins[ipt],pTbins[ipt+1]))\n",
    "    elif (Signal_DNN == \"Isolated\"):\n",
    "        ntrig_histo = file.Get('N_Triggers_pT%1.0f_%1.0f' %(pTbins[ipt],pTbins[ipt+1]))\n",
    "        \n",
    "    else:\n",
    "        DNN_Rgn = int(Signal_DNN) + 2*(1-int(Signal_DNN))\n",
    "        ntrig_histo = file.Get('N_DNN%i_Triggers_pT%1.0f_%1.0f' %(DNN_Rgn,pTbins[ipt],pTbins[ipt+1]))\n",
    "    NTriggers = 1\n",
    "    if not(ntrig_histo == None):\n",
    "        NTriggers = ntrig_histo.GetEntries()\n",
    "    file.Close()\n",
    "    return NTriggers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetEtaProj(filename,prfx,ipt, izt, Signal_DNN=True):\n",
    "    \n",
    "    file = ROOT.TFile(filename)\n",
    "\n",
    "    N_Eta_Bins = 14\n",
    "    \n",
    "    if (Signal_DNN == \"Inclusive\"):\n",
    "        histo2D = file.Get('Inclusive_Correlation__pT%1.0f_%1.0f__zT%1.0f_zT%1.0f' \n",
    "                        %(pTbins[ipt],pTbins[ipt+1],100*zTbins[izt],100*zTbins[izt+1]))\n",
    "        \n",
    "        Eta_Axis = histo2D.GetYaxis()\n",
    "        EtaProjection = histo2D.ProjectionY('Inclusive_EtaProjection__pT_%1.0f_%1.0f__zt_%1.0f_%1.0f' \n",
    "                                      %(pTbins[ipt],pTbins[ipt+1],100*zTbins[izt],\n",
    "                                        100*zTbins[izt+1]),0,-1)\n",
    "    \n",
    "    else:\n",
    "        DNN_Rgn = int(Signal_DNN) + 2*(1-int(Signal_DNN)) #convert bool to DNN_1 (Sgn) or DNN_2 (Bkgd)\n",
    "        histo2D = file.Get('DNN%i_Correlation__pT%1.0f_%1.0f__zT%1.0f_zT%1.0f' \n",
    "                            %(DNN_Rgn,pTbins[ipt],pTbins[ipt+1],100*zTbins[izt],100*zTbins[izt+1]))\n",
    "        \n",
    "        Eta_Axis = histo2D.GetYaxis()\n",
    "        EtaProjection = histo2D.ProjectionY('DNN%i_EtaProjection__pT_%1.0f_%1.0f__zt_%1.0f_%1.0f' \n",
    "                                      %(DNN_Rgn,pTbins[ipt],pTbins[ipt+1],100*zTbins[izt],\n",
    "                                        100*zTbins[izt+1]),0,-1)\n",
    "    \n",
    "    EtaProjection.SetDirectory(0)\n",
    "    #EtaProjection.Scale(1.0/1.2)\n",
    "    \n",
    "    #per trigger yield\n",
    "    ntriggers = Get_NTriggers(filename,ipt, Signal_DNN)\n",
    "    if not(ntriggers == None):\n",
    "        EtaProjection.Scale(1.0/ntriggers)\n",
    "    \n",
    "    file.Close()\n",
    "    \n",
    "    return EtaProjection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetEta_array(filename,prfx,ipt,izt,Signal_DNN=True):\n",
    "    \n",
    "    file = ROOT.TFile(filename)\n",
    "    \n",
    "    if (Signal_DNN == \"Inclusive\"):\n",
    "        histo2D = file.Get('Inclusive_Correlation__pT%1.0f_%1.0f__zT%1.0f_zT%1.0f' \n",
    "                        %(pTbins[ipt],pTbins[ipt+1],100*zTbins[izt],100*zTbins[izt+1]))\n",
    "        \n",
    "        Eta_Axis = histo2D.GetYaxis()\n",
    "        EtaProjection = histo2D.ProjectionY('Inclusive_EtaProjection__pT_%1.0f_%1.0f__zt_%1.0f_%1.0f' \n",
    "                                      %(pTbins[ipt],pTbins[ipt+1],100*zTbins[izt],\n",
    "                                        100*zTbins[izt+1]),0,-1)\\\n",
    "        \n",
    "    elif (Signal_DNN == \"Isolated\"):\n",
    "        histo2D = file.Get('Correlation__pT%1.0f_%1.0f__zT%1.0f_zT%1.0f' \n",
    "                        %(pTbins[ipt],pTbins[ipt+1],100*zTbins[izt],100*zTbins[izt+1]))\n",
    "        \n",
    "        Eta_Axis = histo2D.GetYaxis()\n",
    "        EtaProjection = histo2D.ProjectionY('EtaProjection__pT_%1.0f_%1.0f__zt_%1.0f_%1.0f' \n",
    "                                      %(pTbins[ipt],pTbins[ipt+1],100*zTbins[izt],\n",
    "                                        100*zTbins[izt+1]),0,-1)\n",
    "\n",
    "\n",
    "    \n",
    "    ntriggers = Get_NTriggers(filename,ipt, Signal_DNN)\n",
    "    if not(ntriggers == None):\n",
    "        EtaProjection.Scale(1.0/ntriggers)\n",
    "    \n",
    "    eta_array = root_numpy.hist2array(EtaProjection)\n",
    "    return eta_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        ptbin 0:\n",
      "\n",
      "Isolated       Inclusive\n",
      "0.011544       0.017079\n",
      "0.008828       0.013673\n",
      "0.006256       0.008369\n",
      "0.001853       0.003063\n",
      "0.000317       -0.000595\n",
      "0.000665       0.000596\n",
      "\n",
      "        ptbin 1:\n",
      "\n",
      "Isolated       Inclusive\n",
      "0.007063       0.007949\n",
      "0.003977       0.002699\n",
      "0.002863       0.001602\n",
      "0.000976       0.001151\n",
      "0.001177       0.000881\n",
      "0.000525       0.000347\n",
      "\n",
      "        ptbin 2:\n",
      "\n",
      "Isolated       Inclusive\n",
      "0.002609       0.004687\n",
      "0.001652       0.001849\n",
      "0.000693       0.001563\n",
      "-0.000166       0.000003\n",
      "0.000187       0.000171\n",
      "0.000247       -0.000151\n",
      "\n",
      "        ptbin 3:\n",
      "\n",
      "Isolated       Inclusive\n",
      "0.000161       0.000319\n",
      "-0.000190       0.000465\n",
      "0.000055       -0.000334\n",
      "0.000423       0.000476\n",
      "0.000364       0.000110\n",
      "0.000076       -0.000076\n",
      "\n",
      "0.00706334996263\n"
     ]
    }
   ],
   "source": [
    "Inclusive_eta_array = np.zeros((N_pT_Bins,NzT,N_Eta_Bins))\n",
    "Isolated_eta_array = np.zeros((N_pT_Bins,NzT,N_Eta_Bins))\n",
    "\n",
    "for ptbin in range(4):\n",
    "    #if(ptbin > 0): continue\n",
    "    #ptbin = ptbin+2\n",
    "    print(\"        ptbin %i:\"%(ptbin))\n",
    "    print(\"\")\n",
    "    print(\"Isolated       Inclusive\")\n",
    "\n",
    "    for ztbin in range(6):\n",
    "    \n",
    "        #grab\n",
    "        Inclusive_eta_array[ptbin][ztbin] = GetEta_array(pp_File,\"pp\",ptbin,ztbin,\"Inclusive\") #no subtraction, change DNN\n",
    "        Isolated_eta_array[ptbin][ztbin] = GetEta_array(pp_File,\"pp\",ptbin,ztbin,\"Isolated\")\n",
    "\n",
    "        Inclusive_Diff = Inclusive_eta_array[ptbin][ztbin][:3].sum()-Inclusive_eta_array[ptbin][ztbin][11:].sum()\n",
    "        Isolated_Diff = Isolated_eta_array[ptbin][ztbin][:3].sum()-Isolated_eta_array[ptbin][ztbin][11:].sum()\n",
    "        print(\"%f       %f\"%(Inclusive_Diff,Isolated_Diff))\n",
    "    print(\"\")\n",
    "#print(sig_eta_array)\n",
    "print(Inclusive_eta_array[1][0][:3].sum()-Inclusive_eta_array[1][0][11:].sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eta Projections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TCanvas::Constructor:0: RuntimeWarning: Deleting canvas with same name: canv_phi\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'TObject' object has no attribute 'GetYaxis'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0mTraceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-01107d50aa93>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[1;31m#grab\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m         \u001b[0mhsig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGetEtaProj\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpp_File\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"pp\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mptbin\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mztbin\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"Inclusive\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#no subtraction, change DNN\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m         \u001b[0mhbkg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGetEtaProj\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpp_File\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"pp\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mptbin\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mztbin\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"Inclusive\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-82c294e39e2f>\u001b[0m in \u001b[0;36mGetEtaProj\u001b[1;34m(filename, prfx, ipt, izt, Signal_DNN)\u001b[0m\n\u001b[0;32m      9\u001b[0m                         %(pTbins[ipt],pTbins[ipt+1],100*zTbins[izt],100*zTbins[izt+1]))\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m         \u001b[0mEta_Axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhisto2D\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGetYaxis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m         EtaProjection = histo2D.ProjectionY('Inclusive_EtaProjection__pT_%1.0f_%1.0f__zt_%1.0f_%1.0f' \n\u001b[0;32m     13\u001b[0m                                       %(pTbins[ipt],pTbins[ipt+1],100*zTbins[izt],\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'TObject' object has no attribute 'GetYaxis'"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error in <TFile::TFile>: file InputData/13d_0GeVTrack_paired_large_0GeVTracks_Correlation_Lambda_0_to_300.root does not exist\n"
     ]
    }
   ],
   "source": [
    "for ptbin in range(4):\n",
    "    #if(ptbin > 0): continue\n",
    "    #ptbin = ptbin+2\n",
    "    canvases = ROOT.TCanvas(\"canv_phi\",\"canv_phi\",3500,2500)\n",
    "    canvases.Divide(4,3)\n",
    "    \n",
    "    for ztbin in range(6):\n",
    "    \n",
    "        #grab\n",
    "        hsig = GetEtaProj(pp_File,\"pp\",ptbin,ztbin,\"Inclusive\") #no subtraction, change DNN\n",
    "        hbkg = GetEtaProj(pp_File,\"pp\",ptbin,ztbin,\"Inclusive\")\n",
    " \n",
    "        #same scale\n",
    "        ymax = 1.2*max(hsig.GetMaximum(),hbkg.GetMaximum())\n",
    "        hsig.GetYaxis().SetRangeUser(0,ymax)\n",
    "        hbkg.GetYaxis().SetRangeUser(0,ymax)    \n",
    "    \n",
    "        #Signal\n",
    "        canvases.cd(ztbin*2+1)\n",
    "        hsig.SetMarkerStyle(15)\n",
    "        #hsig.SetMarkerSize(4)\n",
    "        hsig.SetMarkerColor(4)\n",
    "        hsig.Draw()\n",
    "        \n",
    "        #Background\n",
    "        canvases.cd(ztbin*2+2)\n",
    "        hbkg.SetMarkerStyle(15)\n",
    "        #hbkg.SetMarkerSize(4)\n",
    "        hbkg.SetMarkerColor(2)\n",
    "        hbkg.Draw()\n",
    "        #legend.AddEntry(hbkg,\"Low DNN\",\"l\")\n",
    "        #legend.Draw(\"same\")\n",
    "    \n",
    "    canvases.Draw()   \n",
    "    canvases.SaveAs(\"pics/Eta_Same_Mix_Projections_Trigger_pt_%i_Inclusive.png\"%(ptbin))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Numbers of Pairs in zT bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Shower = \"NN\"\n",
    "\n",
    "pPb_File = 'InputData/pPb_SE_NN_Correlation_GMB_Ratio_UnWeight.root'\n",
    "pp_File = 'InputData/pp_SE_NN_Correlation_GMB_Ratio_UnWeight.root'   \n",
    "Files = [pPb_File,pp_File]\n",
    "Systems = [\"pPb\",\"pp\"]\n",
    "purity = [0.276899,0.358741,0.456807,0.476192]\n",
    "\n",
    "NpT = 4\n",
    "pTbins = [12,15,19,26,40]\n",
    "zTbins = [0.05, 0.07670637, 0.11767734, 0.18053204, 0.27695915, 0.42489062, 0.65183634, 1]\n",
    "#####. Total Number of zT bins, max 7  #####\n",
    "NzT = 6\n",
    "#####  Skip First N zT bins  #####\n",
    "zT_offset = 0\n",
    "\n",
    "\n",
    "zT_centers = np.zeros(NzT)\n",
    "zT_widths = np.zeros(NzT)\n",
    "for ztbin in range(zT_offset,NzT+zT_offset):\n",
    "    zT_centers[ztbin-zT_offset] = (zTbins[ztbin]+ zTbins[ztbin+1])/2\n",
    "    zT_widths[ztbin-zT_offset] = (zTbins[ztbin+1]-zTbins[ztbin])\n",
    "    \n",
    "\n",
    "pT_centers = np.zeros(NpT)\n",
    "pT_widths = np.zeros(NpT)\n",
    "for ptbin in range(NpT):\n",
    "    pT_centers[ptbin] = (pTbins[ptbin]+ pTbins[ptbin+1])/2\n",
    "    pT_widths[ptbin] = (pTbins[ptbin]-pTbins[ptbin+1])/1.25\n",
    "print(pT_centers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Get_NTriggers(filename,ipt, Signal_DNN=True): \n",
    "    file = ROOT.TFile(filename)\n",
    "    if (Signal_DNN == \"Inclusive\"):\n",
    "        ntrig_histo = file.Get('N_Triggers_pT%1.0f_%1.0f' %(pTbins[ipt],pTbins[ipt+1]))\n",
    "    else:\n",
    "        DNN_Rgn = int(Signal_DNN) + 2*(1-int(Signal_DNN))\n",
    "        ntrig_histo = file.Get('N_DNN%i_Triggers_pT%1.0f_%1.0f' %(DNN_Rgn,pTbins[ipt],pTbins[ipt+1]))\n",
    "    NTriggers = 1\n",
    "    if not(ntrig_histo == None):\n",
    "        if (Signal_DNN):\n",
    "            NTriggers = ntrig_histo.GetEntries()\n",
    "        else:\n",
    "            if (Use_Weights):\n",
    "                NTriggers = ntrig_histo.GetBinContent(1)\n",
    "            else:\n",
    "                NTriggers = ntrig_histo.GetEntries()\n",
    "    file.Close()\n",
    "    return NTriggers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetCorrelation_Npairs(filename,pt_min,pt_max, izt, Signal_DNN=True):\n",
    "    \n",
    "    file = ROOT.TFile(filename)\n",
    "    \n",
    "    if (Signal_DNN == \"Inclusive\"):\n",
    "        histo2D = file.Get('Correlation__pT%1.0f_%1.0f__zT%1.0f_zT%1.0f' \n",
    "                        %(pt_min[ipt],pt_max,100*zTbins[izt],100*zTbins[izt+1]))\n",
    "    \n",
    "    else:\n",
    "        DNN_Rgn = int(Signal_DNN) + 2*(1-int(Signal_DNN)) #convert bool to DNN_1 (Sgn) or DNN_2 (Bkgd)\n",
    "        \n",
    "        histo2D = file.Get('DNN%i_Correlation__pT%1.0f_%1.0f__zT%1.0f_zT%1.0f' \n",
    "                            %(DNN_Rgn,pt_min,pt_max,100*zTbins[izt],100*zTbins[izt+1]))\n",
    "        \n",
    "    N_Pairs = histo2D.GetEntries()\n",
    "    return N_Pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### N_Trig_Array_pPb = np.zeros(NpT)\n",
    "N_Trig_Array_pp = np.zeros(NpT)\n",
    "\n",
    "N_Trig_Array_Purity_pPb = np.zeros(NpT)\n",
    "N_Trig_Array_Purity_pp = np.zeros(NpT)\n",
    "\n",
    "N_Pairs_Array_pPb = np.zeros((NpT,NzT))\n",
    "N_Pairs_Array_pp = np.zeros((NpT,NzT))\n",
    "\n",
    "N_Pairs_Purity_pPb = np.zeros((NpT,NzT))\n",
    "N_Pairs_Purity_pp = np.zeros((NpT,NzT))\n",
    "\n",
    "\n",
    "for file,SYS in zip(Files,Systems):\n",
    "    \n",
    "    for ipt in range (NpT):\n",
    "        \n",
    "        vars()[\"N_Trig_Array_%s\"%(SYS)][ipt] = Get_NTriggers(file, ipt, True)\n",
    "        vars()[\"N_Trig_Array_Purity_%s\"%(SYS)][ipt] = vars()[\"N_Trig_Array_%s\"%(SYS)][ipt]*purity[ipt]\n",
    "        \n",
    "        for izt in range (NzT):\n",
    "            vars()[\"N_Pairs_Array_%s\"%(SYS)][ipt][izt] = GetCorrelation_Npairs(file,pTbins[ipt],pTbins[ipt+1], izt, True)\n",
    "            vars()[\"N_Pairs_Purity_%s\"%(SYS)][ipt][izt] = (vars()[\"N_Pairs_Array_%s\"%(SYS)][ipt][izt]*purity[ipt])/vars()[\"N_Trig_Array_%s\"%(SYS)][ipt]\n",
    "        \n",
    "print(N_Trig_Array_Purity_pp)\n",
    "print(N_Trig_Array_pp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for SYS in Systems:\n",
    "    if (SYS==\"pPb\"):\n",
    "        sys_color=\"blue\"\n",
    "    else:\n",
    "        sys_color=\"red\"\n",
    "    for ipt in range (NpT):\n",
    "        plt.figure(figsize=(10,7)) \n",
    "        empt, = plt.plot([], [],' ')\n",
    "        bar_zT_pPb = plt.bar(zT_centers,N_Pairs_Purity_pPb[ipt],zT_widths,color=sys_color,alpha=0.5)\n",
    "        bar_zT_pp = plt.bar(zT_centers,N_Pairs_Purity_pp[ipt],zT_widths,color=sys_color)\n",
    "        plt.legend([bar_zT_pPb,bar_zT_pp,empt],[\"pPb No. Pairs\",\"pp No. Pairs\",r'%1.0f < $p_\\mathrm{T}^{\\mathrm{trig}}$ < %1.0f GeV/$c$'%(pTbins[ipt],pTbins[ipt+1])])\n",
    "        plt.title(\"No of Pairs in zT bins in (Purity Scaled)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for SYS in Systems:\n",
    "    if (SYS==\"pPb\"):\n",
    "        sys_color=\"blue\"\n",
    "    else:\n",
    "        sys_color=\"red\"\n",
    "    for ipt in range (NpT):\n",
    "        plt.figure(figsize=(10,7)) \n",
    "        empt, = plt.plot([], [],' ')\n",
    "        bar_pT = plt.bar(pTbins[:NpT],vars()[\"N_Trig_Array_Purity_%s\"%(SYS)],-pT_widths,align='edge',color=sys_color)\n",
    "        plt.legend([bar_pT,empt],[\"No. Triggers (P)\",r'%1.0f < $p_\\mathrm{T}^{\\mathrm{trig}}$ < %1.0f GeV/$c$'%(pTbins[ipt],pTbins[ipt+1])])\n",
    "        plt.title(\"No of Triggers in pT bins (Purity Scaled) in %s\"%(SYS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_pp = []\n",
    "high_pp = []\n",
    "low_pPb = []\n",
    "high_pPb = []\n",
    "ztstring = []\n",
    "for izt in range (zT_offset,NzT+zT_offset):\n",
    "    ztb = izt-zT_offset\n",
    "    ztstring.append(\"%1.2f-%1.2f\"%(zTbins[izt],zTbins[izt+1]))\n",
    "    low_pp.append(GetCorrelation_Npairs('InputData/17q_SE_NN_Correlation.root',12,15,izt,True))\n",
    "    high_pp.append(GetCorrelation_Npairs('InputData/17q_SE_NN_Correlation_HighpT.root',15,20,izt,True))\n",
    "    low_pPb.append(GetCorrelation_Npairs('InputData/13def_SE_NN_Correlation.root',12,15,izt,True))\n",
    "    high_pPb.append(GetCorrelation_Npairs('InputData/13def_SE_NN_Correlation_HighpT.root',15,20,izt,True))\n",
    "\n",
    "print(ztstring)\n",
    "print(low_pp)\n",
    "print(high_pp)\n",
    "print(low_pPb)\n",
    "print(high_pPb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Look at simple $\\Delta \\phi$ Projections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pPb_File = 'InputData/13d_MB_0GeV_NN_15_20.root'\n",
    "# pp_File = 'InputData/17q_MB_0Gev_NN_15_20.root'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####Obtains the phi projection within the eta region (|eta|<0.6)#####\n",
    "def GetPhiProj(filename,prfx,ipt, izt, Signal_DNN=True):\n",
    "    \n",
    "    file = ROOT.TFile(filename)\n",
    "\n",
    "    eta_max = 1.2 #Assuming symmetric eta range\n",
    "    \n",
    "    if (Signal_DNN == \"Inclusive\"):\n",
    "        histo2D = file.Get('Correlation__pT%1.0f_%1.0f__zT%1.0f_zT%1.0f' \n",
    "                        %(pTbins[ipt],pTbins[ipt+1],100*zTbins[izt],100*zTbins[izt+1]))\n",
    "        \n",
    "        Eta_Axis = histo2D.GetYaxis()\n",
    "        PhiProjection = histo2D.ProjectionX('Inclusive_PhiProjection__pT_%1.0f_%1.0f__zt_%1.0f_%1.0f' \n",
    "                                      %(pTbins[ipt],pTbins[ipt+1],100*zTbins[izt],\n",
    "                                        100*zTbins[izt+1]),Eta_Axis.FindBin(-eta_max),Eta_Axis.FindBin(eta_max))\n",
    "    \n",
    "    else:\n",
    "        DNN_Rgn = int(Signal_DNN) + 2*(1-int(Signal_DNN)) #convert bool to DNN_1 (Sgn) or DNN_2 (Bkgd)\n",
    "        histo2D = file.Get('DNN%i_Correlation__pT%1.0f_%1.0f__zT%1.0f_zT%1.0f' \n",
    "                            %(DNN_Rgn,pTbins[ipt],pTbins[ipt+1],100*zTbins[izt],100*zTbins[izt+1]))\n",
    "        \n",
    "        Eta_Axis = histo2D.GetYaxis()\n",
    "        PhiProjection = histo2D.ProjectionX('DNN%i_PhiProjection__pT_%1.0f_%1.0f__zt_%1.0f_%1.0f' \n",
    "                                      %(DNN_Rgn,pTbins[ipt],pTbins[ipt+1],100*zTbins[izt],\n",
    "                                        100*zTbins[izt+1]),Eta_Axis.FindBin(-eta_max),Eta_Axis.FindBin(eta_max))\n",
    "                                            \n",
    "    PhiProjection.SetDirectory(0)\n",
    "    PhiProjection.Rebin(2)\n",
    "    PhiProjection.Scale(1.0/(2*eta_max))\n",
    "    \n",
    "    #per trigger yield\n",
    "#     ntriggers = Get_NTriggers(filename,ipt, Signal_DNN)\n",
    "#     if not(ntriggers == None):\n",
    "#         PhiProjection.Scale(1.0/ntriggers)\n",
    "    \n",
    "    file.Close()\n",
    "    \n",
    "    Phi_Array = np.zeros(len(delta_phi_centers))\n",
    "    Phi_Error_Array = np.zeros(len(delta_phi_centers))\n",
    "    for bin in range(2,9):\n",
    "        Phi_Array[bin-2] = PhiProjection.GetBinContent(bin)\n",
    "        Phi_Error_Array[bin-2] = PhiProjection.GetBinError(bin)\n",
    "    \n",
    "    return Phi_Array, Phi_Error_Array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Systems = [\"pp\",\"p-Pb\"]\n",
    "Files = [pp_File,pPb_File]\n",
    "\n",
    "for sys,ifile in zip(Systems,Files):\n",
    "    fig = plt.figure(figsize=(34,17))\n",
    "    for ipt in range (3):\n",
    "        if (ipt > 0): continue\n",
    "        ipt = ipt+2\n",
    "        for izt in range (zT_offset,NzT+zT_offset):\n",
    "            \n",
    "            ztb = izt-zT_offset\n",
    "\n",
    "            Sig_Phi_Array, Sig_Phi_Error_Array = GetPhiProj(ifile,sys,ipt,izt,True)\n",
    "            Bkg_Phi_Array, Bkg_Phi_Error_Array = GetPhiProj(ifile,sys,ipt,izt,False)\n",
    "                                            \n",
    "                                        #--------------plot--------------------#\n",
    "           \n",
    "            if (NzT ==4):\n",
    "                ax = fig.add_subplot(2,4,(2*ztb+1))\n",
    "            elif (NzT ==6):\n",
    "                ax = fig.add_subplot(3,4,(2*ztb+1))\n",
    "                \n",
    "            fsize = 20\n",
    "\n",
    "            #sig\n",
    "            ax.plot(delta_phi_centers,Sig_Phi_Array,'bo',ms=10)\n",
    "            s_plot = ax.errorbar(delta_phi_centers,Sig_Phi_Array,xerr=phi_width,yerr=Sig_Phi_Error_Array,\n",
    "                                 fmt=None,ecolor='b',label='Signal Region (stat. error)')\n",
    "\n",
    "            plt.xlabel(r'|$\\Delta \\varphi$|',fontsize=fsize+4)\n",
    "            plt.xticks(fontsize=(fsize))\n",
    "            plt.xlim((0.39269908169872414,3.14159))\n",
    "            plt.ylabel(r'$1/N_{\\mathrm{trig}} \\: \\: \\mathrm{d}N/\\mathrm{d}\\Delta\\eta$',fontsize=fsize+2)\n",
    "            plt.ylim((0,1.2*max(Sig_Phi_Array)))\n",
    "            empt, = ax.plot([], [], ' ')\n",
    "            empt2, = ax.plot([],[],' ')\n",
    "            plt.yticks(fontsize=fsize-5)\n",
    "\n",
    "            fill_x = [0,3.14159]\n",
    "#             s_z_line = ax.fill_between(fill_x, Sig_Z_Value-Sig_Z_Error,Sig_Z_Value+Sig_Z_Error,interpolate=False,edgecolor='cyan',linewidth=0.0, alpha=0.3,facecolor='cyan')\n",
    "#             s_le_line = ax.fill_between(fill_x, S_LE-S_LE_Error,S_LE+S_LE_Error,interpolate=False,edgecolor='grey',linewidth=0.0, alpha=0.5,facecolor='grey')\n",
    "\n",
    "            leg = ax.legend([s_plot,empt,empt2],['Signal Region (stat. error)','0.8 <|$\\Delta\\eta$| < 1.4',\n",
    "                'UE Estimate',r'%1.2f < $z_\\mathrm{T}$ < %1.2f'%(zTbins[izt],zTbins[izt+1]),\n",
    "                r'15 < $p_\\mathrm{T}^{\\mathrm{trig}}$ < 20 GeV/$c$'],loc='best',\n",
    "                title = \"Alice Preliminary 5 TeV %s\"%(sys),fontsize=14,frameon=False,numpoints=1)\n",
    "            plt.setp(leg.get_title(),fontsize=20)\n",
    "#             if (sys == 'pp'):\n",
    "#                 leg.set_title(\"ALICE Preliminary, $\\sqrt{s}=$5 TeV %s\"%(sys))\n",
    "#             else:\n",
    "#                 leg.set_title(\"ALICE Preliminary, $\\sqrt{s_{\\mathrm{_{NN}}}}=$5 TeV %s\"%(sys))                \n",
    "#             plt.setp(leg.get_title(),fontsize=14)\n",
    "\n",
    "\n",
    "            #bkg\n",
    "            if (NzT ==4):\n",
    "                ax = fig.add_subplot(2,4,(2*ztb+2))\n",
    "            elif (NzT ==6):\n",
    "                ax = fig.add_subplot(3,4,(2*ztb+2))\n",
    "                \n",
    "            #ax = fig.add_subplot(1,2,1)\n",
    "            plt.xlabel(r'|$\\Delta \\varphi$|',fontsize=fsize+4)\n",
    "            plt.xticks(fontsize=(fsize))\n",
    "            plt.xlim((0.39269908169872414,3.14159))\n",
    "            plt.ylabel(r'$1/N_{\\mathrm{trig}} \\: \\: \\mathrm{d}N/\\mathrm{d}\\Delta\\eta$',fontsize=fsize+2)\n",
    "            plt.ylim((0,1.2*max(Bkg_Phi_Array)))\n",
    "            plt.yticks(fontsize=fsize-5)\n",
    "\n",
    "            fill_x = [0,3.14149]\n",
    "#             b_z_line = plt.fill_between(fill_x, Bkg_Z_Value-Bkg_Z_Error,Bkg_Z_Value+Bkg_Z_Error,interpolate=False,edgecolor='cyan',linewidth=0.0, alpha=0.3,facecolor='cyan')\n",
    "#             b_le_line = plt.fill_between(fill_x, Bkg_LE-Bkg_LE_Error,Bkg_LE+Bkg_LE_Error,interpolate=False,edgecolor='grey',linewidth=0.0, alpha=0.5,facecolor='grey')\n",
    "\n",
    "            ax.plot(delta_phi_centers,Bkg_Phi_Array,'ro',ms=10)\n",
    "            b_plot = ax.errorbar(delta_phi_centers,Bkg_Phi_Array,xerr=phi_width,yerr=Bkg_Phi_Error_Array,fmt=None,ecolor='r')\n",
    "\n",
    "            leg = ax.legend([b_plot,empt,empt2],['Bkg Region (stat. error)',r'%1.2f < $z_\\mathrm{T}$ < %1.2f'%(zTbins[izt],\n",
    "                zTbins[izt+1]),r'15 < $p_\\mathrm{T}^{\\mathrm{trig}}$ < 20 GeV/$c$'],loc='best',\n",
    "                title = \"Alice Preliminary 5 TeV %s\"%(sys),fontsize=14,frameon=False,numpoints=1)\n",
    "            plt.setp(leg.get_title(),fontsize=20)\n",
    "\n",
    "     \n",
    "    print(\"\")\n",
    "    #return\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pTbins[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Shower_Shape = \"NN\"\n",
    "Shower_Shape = \"L0\"\n",
    "\n",
    "if (Shower_Shape==\"NN\"):\n",
    "    File = 'InputData/13d_SE_NN_Correlation.root'\n",
    "elif (Shower_Shape==\"L0\"):\n",
    "    File = 'InputData/13d_SE_L0_Correlation.root'\n",
    "file = ROOT.TFile(File)\n",
    "\n",
    "N_Sig_histo = file.Get(\"N_DNN1_Triggers_pT12_15\")\n",
    "N_Sig = N_Sig_histo.GetEntries()\n",
    "N_BKG_histo = file.Get(\"N_DNN2_Triggers_pT12_15\")\n",
    "N_BKG = N_BKG_histo.GetEntries()\n",
    "\n",
    "\n",
    "SIG = file.Get(\"Signal_pT_Dist\")\n",
    "SIG.Rebin(5)\n",
    "print(SIG.GetEntries())\n",
    "BKGD = file.Get(\"BKGD_pT_Dist\")\n",
    "BKGD.Rebin(5)\n",
    "print(BKGD.GetEntries())\n",
    "BKGD_W = file.Get(\"BKGD_pT_Dist_Weighted\")\n",
    "BKGD_W.Rebin(5)\n",
    "\n",
    "#SIG.Rebin(10)\n",
    "Signal = root_numpy.hist2array(SIG)\n",
    "S_Scale = Signal.sum(axis=0)\n",
    "Signal = Signal/S_Scale\n",
    "\n",
    "\n",
    "#BKGD.Rebin(10)\n",
    "Background = root_numpy.hist2array(BKGD)\n",
    "B_Scale = Background.sum(axis=0)\n",
    "Background = Background/B_Scale\n",
    "\n",
    "#BKGD_W.Rebin(10)\n",
    "Background_W = root_numpy.hist2array(BKGD_W)\n",
    "B_Scale_W = Background_W.sum(axis=0)\n",
    "Background_W = Background_W/B_Scale_W\n",
    "\n",
    "N_Bins = SIG.GetSize() - 2 #Ignero under/overflow\n",
    "S_Error = np.zeros(N_Bins)\n",
    "B_Error = np.zeros(N_Bins)\n",
    "BW_Error = np.zeros(N_Bins)\n",
    "for i in range(1,N_Bins+1):\n",
    "    S_Error[i-1] = SIG.GetBinError(i)\n",
    "    print(SIG.GetBinError(i))\n",
    "    B_Error[i-1] = BKGD.GetBinError(i)\n",
    "    BW_Error[i-1] = BKGD_W.GetBinError(i)\n",
    "    \n",
    "S_Error = S_Error/S_Scale\n",
    "B_Error = B_Error/B_Scale\n",
    "BW_Error = BW_Error/B_Scale_W\n",
    "    \n",
    "print(Signal.size)\n",
    "print(S_Error.size)\n",
    "\n",
    "pT_Axis = np.linspace(10,40,N_Bins)\n",
    "\n",
    "fig = plt.figure(figsize=(10,7))\n",
    "if (Shower_Shape==\"NN\"):\n",
    "    plt.errorbar(pT_Axis,Signal,yerr = S_Error,label=\"Signal Region Clusters (0.55 < NN < 0.85)\")\n",
    "    plt.errorbar(pT_Axis,Background,yerr = B_Error,label=\"Background Region Clusters (NN < 0.4)\")\n",
    "    plt.errorbar(pT_Axis,Background_W,yerr = BW_Error,fmt = \"--r\",label=\"Weighted Background Clusters (NN < 0.4)\")\n",
    "    plt.title(r\"Isolated Cluster $p_{\\mathrm{T}}$ Distribution  $DNN$\")\n",
    "\n",
    "elif (Shower_Shape==\"L0\"):\n",
    "    plt.errorbar(pT_Axis,Signal,yerr = S_Error,label=\"Signal Region Clusters ($\\lambda^{2}_{0}$ < 0.3)\")\n",
    "    plt.errorbar(pT_Axis,Background,yerr = B_Error,label=\"Background Region Clusters ($\\lambda^{2}_{0}$ > 0.4)\")\n",
    "    plt.errorbar(pT_Axis,Background_W,yerr = BW_Error,fmt = \"--r\",label=\"Weighted Bkg Region Clusters ($\\lambda^{2}_{0}$ > 0.4)\")\n",
    "    plt.title(r\"Isolated Cluster $p_{\\mathrm{T}}$ Distribution  $\\lambda^{2}_{0}$\")\n",
    "    #plt.ylim(0,0.01)\n",
    "    \n",
    "plt.xlabel(r'Cluster $p_{\\mathrm{T}}$')\n",
    "plt.ylabel(r'$\\frac{1}{N_{\\gamma}}\\cdot dN$')\n",
    "plt.legend()\n",
    "fig.savefig('pics/Cluster_pT_Weighted.pdf', bbox_inches='tight')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Shower_Shape = \"NN\"\n",
    "Shower_Shape = \"L0\"\n",
    "\n",
    "if (Shower_Shape==\"NN\"):\n",
    "    File = 'InputData/17q_SE_NN_Correlation.root'\n",
    "elif (Shower_Shape==\"L0\"):\n",
    "    File = 'InputData/13d_SE_L0_Correlation.root'\n",
    "file = ROOT.TFile(File)\n",
    "\n",
    "SIG = file.Get(\"hweight\")\n",
    "print(SIG)\n",
    "print(SIG.GetEntries())\n",
    "Signal = root_numpy.hist2array(SIG)\n",
    "S_Error = np.zeros(40)\n",
    "for i in range(1,41):\n",
    "    S_Error[i-1] = SIG.GetBinError(i)\n",
    "    \n",
    "\n",
    "pT_Axis = np.linspace(10,50,40)\n",
    "fig = plt.figure(figsize=(10,7))\n",
    "\n",
    "if (Shower_Shape==\"NN\"):\n",
    "    plt.errorbar(pT_Axis,Signal,yerr = S_Error,label=\"Signal Clusters ($0.5 < NN < 0.85)\")\n",
    "    \n",
    "elif (Shower_Shape==\"L0\"):\n",
    "    plt.errorbar(pT_Axis,Signal,yerr = S_Error,label=\"Cluster pT weights\")\n",
    "    plt.title(r\"Isolated Cluster $p_{\\mathrm{T}}$ Weights\")\n",
    "\n",
    "    \n",
    "plt.xlabel(r'Cluster $p_{\\mathrm{T}}$')\n",
    "plt.ylabel(r'Cluster $p_{\\mathrm{T}}$ Weight')\n",
    "plt.xlim(12,40)\n",
    "#plt.ylim(0,1.2)\n",
    "plt.legend()\n",
    "fig.savefig('pics/Weights.pdf', bbox_inches='tight')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare ME Inclusive and Signal Correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Shower_Shape = \"NN\"\n",
    "\n",
    "if (Shower_Shape==\"NN\"):\n",
    "    File = 'InputData/13f_MB_0GeV_Skim_Correlation_NN.root'\n",
    "elif (Shower_Shape==\"L0\"):\n",
    "    File = 'InputData/17q_MB_0GeV_Skim_Correlation.root'\n",
    "file = ROOT.TFile(File)\n",
    "\n",
    "SIG_2D = file.Get(\"DNN1_Correlation__pT12_15__zT12_zT18\")\n",
    "BKG_2D = file.Get(\"DNN2_Correlation__pT12_15__zT12_zT18\")\n",
    "INC_2D = file.Get(\"Correlation__pT12_15__zT12_zT18\")\n",
    "\n",
    "SIG = SIG_2D.ProjectionX(\"Sig_Phi\",0,-1)\n",
    "BKG = BKG_2D.ProjectionX(\"Bkg_Phi\",0,-1)\n",
    "INC = INC_2D.ProjectionX(\"Inc_Phi\",0,-1)\n",
    "\n",
    "SIG.Divide(INC)\n",
    "BKG.Divide(INC)\n",
    "\n",
    "Signal = root_numpy.hist2array(SIG)\n",
    "Background = root_numpy.hist2array(BKG)\n",
    "\n",
    "N_Bins = SIG.GetSize() - 2 #Ignero under/overflow\n",
    "print(N_Bins)\n",
    "S_Error = np.zeros(N_Bins)\n",
    "B_Error = np.zeros(N_Bins)\n",
    "for i in range(1,N_Bins+1):\n",
    "    S_Error[i-1] = SIG.GetBinError(i)\n",
    "    B_Error[i-1] = BKG.GetBinError(i)\n",
    "\n",
    "Corr_Axis = np.linspace(0,3.14159,N_Bins)    \n",
    "\n",
    "print(SIG)\n",
    "\n",
    "if (Shower_Shape==\"NN\"):\n",
    "    plt.errorbar(Corr_Axis,Signal,yerr = S_Error,label=\"Signal Clusters ($0.5 < NN < 0.85)\")\n",
    "    plt.title(r\"Isolated Cluster $p_{\\mathrm{T}}$ Distribution  $DNN$\")\n",
    "    #plt.ylim(0.5,0.58)\n",
    "    plt.ylim(0.0,0.33)\n",
    "\n",
    "elif (Shower_Shape==\"L0\"):\n",
    "    plt.errorbar(Corr_Axis,Signal,yerr = S_Error,label=\"Signal Clusters ($\\lambda^{2}_{0}$ < 0.4)\")\n",
    "\n",
    "Signal = root_numpy.hist2array(SIG)\n",
    "Background = root_numpy.hist2array(SIG)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "File_NN = 'InputData/17q_MB_0GeV_Skim_Correlation.root'\n",
    "#File_NN = 'InputData/13f_SE_NN_Correlation_GMB_Ratio.root'\n",
    "File_L0 = 'InputData/17q_MB_0GeV_Skim_Correlation_L0.root'\n",
    "\n",
    "file_NN = ROOT.TFile(File_NN)\n",
    "file_L0 = ROOT.TFile(File_L0)\n",
    "\n",
    "\n",
    "SIG_2D_NN = file_NN.Get(\"DNN1_Correlation__pT12_15__zT12_zT18\")\n",
    "SIG_2D_L0 = file_L0.Get(\"DNN1_Correlation__pT12_15__zT12_zT18\")\n",
    "\n",
    "BKG_2D_NN = file_NN.Get(\"DNN2_Correlation__pT12_15__zT12_zT18\")\n",
    "BKG_2D_L0 = file_L0.Get(\"DNN2_Correlation__pT12_15__zT12_zT18\")\n",
    "\n",
    "c = ROOT.TCanvas(\"myCanvasName\",\"The Canvas Title\",800,600)\n",
    "BKG_2D_NN.Draw(\"SURF2\")\n",
    "c.Draw()\n",
    "\n",
    "INC_2D_NN = file_NN.Get(\"Correlation__pT12_15__zT12_zT18\")\n",
    "INC_2D_L0 = file_L0.Get(\"Correlation__pT12_15__zT12_zT18\")\n",
    "\n",
    "SIG_NN = SIG_2D_NN.ProjectionX(\"Sig_Phi\",0,-1)\n",
    "SIG_L0 = SIG_2D_L0.ProjectionX(\"Sig_Phi\",0,-1)\n",
    "\n",
    "BKG_NN = BKG_2D_NN.ProjectionX(\"Bkg_Phi\",0,-1)\n",
    "BKG_L0 = BKG_2D_L0.ProjectionX(\"Bkg_Phi\",0,-1)\n",
    "\n",
    "INC_NN = INC_2D_NN.ProjectionX(\"Inc_Phi\",0,-1)\n",
    "INC_L0 = INC_2D_L0.ProjectionX(\"Inc_Phi\",0,-1)\n",
    "\n",
    "SIG_L0.Divide(INC_NN)\n",
    "BKG_NN.Divide(BKG_L0)\n",
    "\n",
    "Signal = root_numpy.hist2array(SIG_L0)\n",
    "print(Signal)\n",
    "Background = root_numpy.hist2array(BKG_NN)\n",
    "\n",
    "N_Bins = SIG_NN.GetSize() - 2 #Ignero under/overflow\n",
    "print(N_Bins)\n",
    "S_Error = np.zeros(N_Bins)\n",
    "B_Error = np.zeros(N_Bins)\n",
    "for i in range(1,N_Bins+1):\n",
    "    S_Error[i-1] = SIG_NN.GetBinError(i)\n",
    "    B_Error[i-1] = BKG_NN.GetBinError(i)\n",
    "\n",
    "Corr_Axis = np.linspace(0,3.14159,N_Bins)    \n",
    "\n",
    "#plt.errorbar(Corr_Axis,Signal,yerr = S_Error,label=\"Signal Clusters ($0.5 < NN < 0.85)\")\n",
    "#plt.title(r\"Isolated Cluster $p_{\\mathrm{T}}$ Distribution  $DNN$\")\n",
    "\n",
    "plt.errorbar(Corr_Axis,Signal,yerr = S_Error,label=\"Signal Clusters ($0.5 < NN < 0.85)\")\n",
    "plt.title(r\"Isolated Cluster $p_{\\mathrm{T}}$ Distribution  $DNN$\")\n",
    "#plt.ylim(0.99,1.01)\n",
    "plt.ylim(0.2,0.4)\n",
    "    \n",
    "print(\"hi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Get_NTriggers(filename,ipt, Signal_DNN=True): \n",
    "    file = ROOT.TFile(filename)\n",
    "    if (Signal_DNN == \"Inclusive\"):\n",
    "        ntrig_histo = file.Get('N_Triggers_pT%1.0f_%1.0f' %(pTbins[ipt],pTbins[ipt+1]))\n",
    "    else:\n",
    "        DNN_Rgn = int(Signal_DNN) + 2*(1-int(Signal_DNN))\n",
    "        ntrig_histo = file.Get('N_DNN%i_Triggers_pT%1.0f_%1.0f' %(DNN_Rgn,pTbins[ipt],pTbins[ipt+1]))\n",
    "    NTriggers = 1\n",
    "    if not(ntrig_histo == None):\n",
    "        if (Signal_DNN):\n",
    "            NTriggers = ntrig_histo.GetEntries()\n",
    "        else:\n",
    "            if (Use_Weights):\n",
    "                NTriggers = ntrig_histo.GetBinContent(1)\n",
    "            else:\n",
    "                NTriggers = ntrig_histo.GetEntries()\n",
    "    file.Close()\n",
    "    return NTriggers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (Shower_Shape==\"NN\"):\n",
    "    File = 'InputData/13f_MB_0GeV_Skim_Correlation_NN.root'\n",
    "elif (Shower_Shape==\"L0\"):\n",
    "    File = 'InputData/17q_MB_0GeV_Skim_Correlation.root'\n",
    "file = ROOT.TFile(File)\n",
    "\n",
    "pT_Bins = [12,15,19,26,40]\n",
    "N_pT_Bins = len(pT_Bins)\n",
    "pT_Centres =  np.zeros[N_pT_Bins]\n",
    "N_Sig_Triggers = np.zeros(N_pT_Bins)\n",
    "N_Bkg_Trigs = np.zeros(N_pT_Bins)\n",
    "N_Pairs = np.zeros((N_pT_Bins,NzT))\n",
    "\n",
    "for ipt in range (N_pT_Bins):\n",
    "    pT_Centers[ipt] = (pT_Bins[ipt] + pT_Bins[ipt+1])/2\n",
    "    N_Sig_Trigs[ipt] = Get_NTriggers(File,ipt,True)\n",
    "    N_Bkg_Trigs[ipt] = Get_NTriggers(File,ipt,True)\n",
    "    \n",
    "plt.plot(pT_Centers, N_Sig_Trigs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyROOT",
   "language": "python",
   "name": "pyroot"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
